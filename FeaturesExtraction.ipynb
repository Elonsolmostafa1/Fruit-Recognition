{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc27721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn import svm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from skimage.filters import threshold_yen\n",
    "from skimage.exposure import rescale_intensity\n",
    "from scipy.stats import skew\n",
    "from itertools import chain\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "117b05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apple_training_data='dataset\\\\Apples\\\\Train\\\\*.jpg'\n",
    "Orange_training_data='dataset\\\\Oranges\\\\Train\\\\*.jpg'\n",
    "Mango_training_data='dataset\\\\Mangoes\\\\Train\\\\*.jpg'\n",
    "Test_data='dataset\\\\test\\\\*.jpg'\n",
    "\n",
    "Apple_hue_arr = []   #Info of hue of  each apple pic\n",
    "Orange_hue_arr = []  #Info of hue of  each orange pic\n",
    "Mango_hue_arr = []   #Info of hue of  each mango pic\n",
    "Apple_des_list = []\n",
    "Orange_des_list = []\n",
    "Mango_des_list = []\n",
    "sift = cv2.SIFT_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53c0be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_glcm_features(gray_scale_img):\n",
    "    \"\"\"\n",
    "    Given a grayscale image with graylevels from 0 - 255, this function returns the contrast\n",
    "    and the homogeneity features of the image with the help of GLCM\n",
    "    \"\"\"\n",
    "    # Tip: Make sure you understand the input-output of everything you write, \n",
    "    # not doing that results in bugs that make you believe the lab is long\n",
    "    \n",
    "    #size of co-occ matrix = number of gray levels\n",
    "    image_array = np.array(gray_scale_img)\n",
    "    #print('first pixel= ', image_array[0][0])\n",
    "    coocurrence_matrix = greycomatrix(image_array, [1], [0])\n",
    "    contrast = greycoprops(coocurrence_matrix, 'contrast')\n",
    "    homogeneity = greycoprops(coocurrence_matrix, 'homogeneity')\n",
    "    #mean = greycoprops(coocurrence_matrix, 'mean')\n",
    "    energy = greycoprops(coocurrence_matrix, 'energy')\n",
    "    #entropy = greycoprops(coocurrence_matrix, 'entropy')\n",
    "    #variance = greycoprops(coocurrence_matrix, 'variance')\n",
    "    correlation = greycoprops(coocurrence_matrix, 'correlation')\n",
    "    return contrast, homogeneity, energy, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9136bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(Apple_training_data):    \n",
    "    img = cv2.imread(file)  #read apple images\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  #convert from RBG to HSV\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contrast, homogeneity, energy, correlation= get_all_glcm_features((img_gray * 255).astype(np.uint8))\n",
    "    kpts, des = sift.detectAndCompute(img_gray,None)\n",
    "    if len(kpts) < 1:\n",
    "        no_kpts = np.zeros((1, sift.descriptorSize()), np.float32)\n",
    "        Apple_des_list.append((file, no_kpts))\n",
    "    else:\n",
    "        Apple_des_list.append((file, des)) \n",
    "    h,s,v=cv2.split(img)  #Split the the channels of each image\n",
    "    hue_mean=np.mean(h)  #calculate the mean of hue channel of each image\n",
    "    hue_var=np.var(h)    #calculate the var of hue channel of each image\n",
    "    flatten_h = list(np.concatenate(h).flat)  #convert the 2-D image to 1-D image\n",
    "    flatten_s = list(np.concatenate(s).flat)\n",
    "    hue_skewness=skew(flatten_h)   #calculate the skewness of hue channel of each image\n",
    "    image_hue_info=[]\n",
    "    image_hue_info.append(hue_mean)\n",
    "    image_hue_info.append(hue_var)\n",
    "    image_hue_info.append(hue_skewness)\n",
    "    #######################################################################\n",
    "    image_hue_info.append(contrast[0][0])\n",
    "    image_hue_info.append(homogeneity[0][0])\n",
    "    image_hue_info.append(energy[0][0])\n",
    "    image_hue_info.append(correlation[0][0])\n",
    "    #########################################################################\n",
    "    Apple_hue_arr.append(image_hue_info)\n",
    "print(len(Apple_hue_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f10fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = Apple_des_list[0][1]\n",
    "for file, descriptor in Apple_des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a6613cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)\n",
    "\n",
    "k = 60  #k means awal 60 clusters\n",
    "voc, variance = kmeans(descriptors_float, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56f14c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apple_features = np.zeros((72, k), \"float32\")\n",
    "for i in range(72):\n",
    "    words, distance = vq(Apple_des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        Apple_features[i][w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "791efcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apples_all_features=np.concatenate((Apple_hue_arr,Apple_features.tolist()),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "419b11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(Orange_training_data):    \n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contrast, homogeneity, energy, correlation= get_all_glcm_features((img_gray * 255).astype(np.uint8))\n",
    "    kpts, des = sift.detectAndCompute(img_gray,None)\n",
    "    if len(kpts) < 1:\n",
    "        no_kpts = np.zeros((1, sift.descriptorSize()), np.float32)\n",
    "        Orange_des_list.append((file, no_kpts))\n",
    "    else:\n",
    "        Orange_des_list.append((file, des)) \n",
    "    h,s,v=cv2.split(img)\n",
    "    hue_mean=np.mean(h)  #calculate the mean of hue channel of each image\n",
    "    hue_var=np.var(h) \n",
    "    flatten_h = list(np.concatenate(h).flat)\n",
    "    hue_skewness=skew(flatten_h)\n",
    "    image_hue_info=[]\n",
    "    image_hue_info.append(hue_mean)\n",
    "    image_hue_info.append(hue_var)\n",
    "    image_hue_info.append(hue_skewness)\n",
    "    #######################################################################\n",
    "    image_hue_info.append(contrast[0][0])\n",
    "    image_hue_info.append(homogeneity[0][0])\n",
    "    image_hue_info.append(energy[0][0])\n",
    "    image_hue_info.append(correlation[0][0])\n",
    "    #########################################################################\n",
    "    Orange_hue_arr.append(image_hue_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "491e337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = Orange_des_list[0][1]\n",
    "for file, descriptor in Orange_des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e963b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)\n",
    "\n",
    "k = 60  #k means awal 60 clusters\n",
    "voc, variance = kmeans(descriptors_float, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3dc6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "Orange_features = np.zeros((70, k), \"float32\")\n",
    "for i in range(70):\n",
    "    words, distance = vq(Orange_des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        Orange_features[i][w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e56a7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oranges_all_features=np.concatenate((Orange_hue_arr,Orange_features.tolist()),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12fba653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(Mango_training_data):    \n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contrast, homogeneity, energy, correlation= get_all_glcm_features((img_gray * 255).astype(np.uint8))\n",
    "    kpts, des = sift.detectAndCompute(img_gray,None)\n",
    "    if len(kpts) < 1:\n",
    "        no_kpts = np.zeros((1, sift.descriptorSize()), np.float32)\n",
    "        Mango_des_list.append((file, no_kpts))\n",
    "    else:\n",
    "        Mango_des_list.append((file, des)) \n",
    "    h,s,v=cv2.split(img)\n",
    "    hue_mean=np.mean(h)\n",
    "    hue_var=np.var(h)\n",
    "    flatten_h = list(np.concatenate(h).flat)\n",
    "    hue_skewness=skew(flatten_h)\n",
    "    image_hue_info=[]\n",
    "    image_hue_info.append(hue_mean)\n",
    "    image_hue_info.append(hue_var)\n",
    "    image_hue_info.append(hue_skewness)\n",
    "    #######################################################################\n",
    "    image_hue_info.append(contrast[0][0])\n",
    "    image_hue_info.append(homogeneity[0][0])\n",
    "    image_hue_info.append(energy[0][0])\n",
    "    image_hue_info.append(correlation[0][0])\n",
    "    #########################################################################\n",
    "    Mango_hue_arr.append(image_hue_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3551c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = Mango_des_list[0][1]\n",
    "for file, descriptor in Mango_des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47d45309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)\n",
    "\n",
    "k = 60  #k means awal 60 clusters\n",
    "voc, variance = kmeans(descriptors_float, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bddbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Mango_features = np.zeros((78, k), \"float32\")\n",
    "for i in range(78):\n",
    "    words, distance = vq(Mango_des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        Mango_features[i][w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae3a5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mangos_all_features=np.concatenate((Mango_hue_arr,Mango_features.tolist()),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98f14307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "['Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Apple', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Orange', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango', 'Mango']\n",
      "220\n",
      "[48.96833125, 1190.4076741736064, -0.267091441509736, 90.96823707256047, 0.5237285380681689, 0.15935572676245768, 0.9856370567780426, 78.0, 133.0, 95.0, 125.0, 75.0, 82.0, 109.0, 232.0, 178.0, 147.0, 109.0, 81.0, 171.0, 164.0, 89.0, 58.0, 269.0, 153.0, 128.0, 116.0, 114.0, 109.0, 172.0, 90.0, 183.0, 115.0, 79.0, 84.0, 69.0, 19.0, 74.0, 97.0, 65.0, 93.0, 116.0, 147.0, 102.0, 100.0, 134.0, 92.0, 84.0, 89.0, 17.0, 96.0, 90.0, 123.0, 82.0, 91.0, 212.0, 89.0, 33.0, 83.0, 78.0, 142.0, 77.0, 179.0, 187.0, 156.0, 187.0, 146.0]\n"
     ]
    }
   ],
   "source": [
    "#print(len(Apple_hue_arr),len(Orange_hue_arr),len(Mango_hue_arr))\n",
    "a=[\"Apple\"]*len(Apples_all_features)\n",
    "o=[\"Orange\"]*len(Oranges_all_features)\n",
    "m=[\"Mango\"]*len(Mangos_all_features)\n",
    "all_labels=a+o+m\n",
    "print(len(all_labels))\n",
    "print(all_labels)\n",
    "\n",
    "all_features= Apples_all_features + Oranges_all_features + Mangos_all_features\n",
    "print(len(all_features))\n",
    "print(all_features[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff05e0",
   "metadata": {},
   "source": [
    "#pca\n",
    "pca = PCA()\n",
    "x_scaled_pca = pca.fit_transform(all_features)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_*100,decimals=1)\n",
    "labels =[str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var)\n",
    "plt.tick_params(\n",
    "    axis='x',\n",
    "    which='both',\n",
    "    bottom= False,\n",
    "    top= False,\n",
    "    labelbottom=False)\n",
    "plt.ylabel('percentage of explained variance')\n",
    "plt.xlabel('principal Components')\n",
    "plt.title('scree plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "851a0119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [0.5, 1, 10, 100],\n",
    "        'gamma': ['scale',1,0.1,0.01,0.001,0.0001],\n",
    "        'kernel': ['rbf','linear']\n",
    "    },\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    svm.SVC(),\n",
    "    param_grid,\n",
    "    cv=20,\n",
    "    scoring='accuracy',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "#print(len(all_features_scalled),len(y_train))\n",
    "all_features_scaled = sc().fit_transform(all_features)\n",
    "\n",
    "optimal_params.fit(all_features_scaled,all_labels)\n",
    "print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80ec85f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, random_state=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm_rbf =  svm.SVC(random_state=0,C=0.5,gamma='scale',kernel='rbf')\n",
    "clf_svm_rbf.fit(all_features_scaled,all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c2f74",
   "metadata": {},
   "source": [
    "all_features_scalled=scale(all_features)\n",
    "clf_linear = svm.SVC(kernel='linear').fit(all_features_scalled[0:220,0:3].tolist(),all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1225ce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81.  14.  55.  28.   7. 151.  24.  61.  54.  53.  12.  39.   9.  15.\n",
      "  38.   1.  23.  37.  58.  39.  58.  62.  70.  20.  39.  73.  15.  26.\n",
      " 170.  11.  29.  12.  28.  22.  42.  33.  28.   1.  47.  73.  23.  42.\n",
      "  27.  18.  24.  11.  61.  12.  56.  52.  53.  21.  19.  61.  56.  51.\n",
      "  36.  42.  25.  57.] [-0.25846954 -0.57475712 -0.06088423 -0.61688323 -0.70619813  0.55082274\n",
      " -0.67425702 -0.30658218 -0.02908573 -0.21904779 -0.65964596 -0.5391918\n",
      " -0.67957943 -0.6016993  -0.6627812  -0.63094987 -0.62601596 -0.50883097\n",
      " -0.19604642 -0.45338123 -0.41712416 -0.27677757  0.09316418 -0.58734673\n",
      " -0.47915511  0.06046792 -0.62154992 -0.58839075  0.93215911 -0.64358028\n",
      "  0.23911544 -0.58359234 -0.55161507 -0.37657265 -0.53161841 -0.51090759\n",
      " -0.54083358 -0.59136666 -0.0976016  -0.35725953 -0.54125705 -0.34062461\n",
      "  0.99665648 -0.62268594 -0.58781443 -0.58894897 -0.2968477  -0.60481304\n",
      " -0.20998927 -0.57477009 -0.72459579 -0.3546952  -0.47346692 -0.07139934\n",
      " -0.2665754   0.01949903 -0.44134485 -0.32715426 -0.4604081  -0.37508895]\n",
      "[54.9641375, 741.0903347144275, -0.1376370610488463, 48.03567347789825, 0.468162347137313, 0.07662212868407726, 0.9955644102805209] [ 1.00617654  0.03202165 -0.45410068 -0.46958581 -1.36131486 -1.06762876\n",
      "  0.70152247]\n"
     ]
    }
   ],
   "source": [
    "Test_des_list=[]\n",
    "Test_hue_arr=[]\n",
    "for file in glob.glob(Test_data):    \n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contrast, homogeneity, energy, correlation= get_all_glcm_features((img_gray * 255).astype(np.uint8))\n",
    "    kpts, des = sift.detectAndCompute(img_gray,None)\n",
    "    if len(kpts) < 1:\n",
    "        no_kpts = np.zeros((1, sift.descriptorSize()), np.float32)\n",
    "        Test_des_list.append((file, no_kpts))\n",
    "    else:\n",
    "        Test_des_list.append((file, des)) \n",
    "    h,s,v=cv2.split(img)\n",
    "    hue_mean=np.mean(h)  #calculate the mean of hue channel of each image\n",
    "    hue_var=np.var(h) \n",
    "    flatten_h = list(np.concatenate(h).flat)\n",
    "    hue_skewness=skew(flatten_h)\n",
    "    image_hue_info=[]\n",
    "    image_hue_info.append(hue_mean)\n",
    "    image_hue_info.append(hue_var)\n",
    "    image_hue_info.append(hue_skewness)\n",
    "    #######################################################################\n",
    "    image_hue_info.append(contrast[0][0])\n",
    "    image_hue_info.append(homogeneity[0][0])\n",
    "    image_hue_info.append(energy[0][0])\n",
    "    image_hue_info.append(correlation[0][0])\n",
    "    #########################################################################\n",
    "    Test_hue_arr.append(image_hue_info) \n",
    "\n",
    "\n",
    "\n",
    "    # Stack all the descriptors vertically in a numpy array\n",
    "descriptors = Test_des_list[0][1]\n",
    "for file, descriptor in Test_des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)\n",
    "\n",
    "k = 60  #k means awal 60 clusters\n",
    "voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Test_features = np.zeros((len(Test_hue_arr), k), \"float32\")\n",
    "for i in range(len(Test_hue_arr)):\n",
    "    words, distance = vq(Test_des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        Test_features[i][w] += 1\n",
    "\n",
    "\n",
    "\n",
    "Test_features_scaled = scale(Test_features.tolist())\n",
    "print(Test_features[0],Test_features_scaled[0])\n",
    "\n",
    "Test_hue_arr_scaled = scale(Test_hue_arr)\n",
    "print(Test_hue_arr[0],Test_hue_arr_scaled[0])\n",
    "\n",
    "Test_all_features=np.concatenate((Test_hue_arr_scaled,Test_features_scaled.tolist()),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac54e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf ['Orange' 'Orange' 'Orange' 'Mango' 'Mango' 'Mango' 'Mango' 'Apple'\n",
      " 'Apple' 'Apple']\n"
     ]
    }
   ],
   "source": [
    "#predict the fruit type in a new image\n",
    "#print(\"LINEAR\",clf_linear.predict(Test_all_features))\n",
    "print(\"rbf\",clf_svm_rbf.predict(Test_all_features))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

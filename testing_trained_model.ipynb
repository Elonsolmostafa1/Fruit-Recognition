{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "from sklearn import svm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from skimage.filters import threshold_yen\n",
    "from skimage.exposure import rescale_intensity\n",
    "from scipy.stats import skew\n",
    "from itertools import chain\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "# load the model from disk\n",
    "filename = 'frut_recognation_model.sav'\n",
    "clf_svm_rbf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_glcm_features(gray_scale_img):\n",
    "    \"\"\"\n",
    "    Given a grayscale image with graylevels from 0 - 255, this function returns the contrast\n",
    "    and the homogeneity features of the image with the help of GLCM\n",
    "    \"\"\"\n",
    "    # Tip: Make sure you understand the input-output of everything you write, \n",
    "    # not doing that results in bugs that make you believe the lab is long\n",
    "    \n",
    "    #size of co-occ matrix = number of gray levels\n",
    "    image_array = np.array(gray_scale_img)\n",
    "    #print('first pixel= ', image_array[0][0])\n",
    "    coocurrence_matrix = greycomatrix(image_array, [1], [0])\n",
    "    contrast = greycoprops(coocurrence_matrix, 'contrast')\n",
    "    homogeneity = greycoprops(coocurrence_matrix, 'homogeneity')\n",
    "    #mean = greycoprops(coocurrence_matrix, 'mean')\n",
    "    energy = greycoprops(coocurrence_matrix, 'energy')\n",
    "    #entropy = greycoprops(coocurrence_matrix, 'entropy')\n",
    "    #variance = greycoprops(coocurrence_matrix, 'variance')\n",
    "    correlation = greycoprops(coocurrence_matrix, 'correlation')\n",
    "    return contrast, homogeneity, energy, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.421264962709344, 3412.6617333374807, 1.7043657981202305, 62.783856104908736, 0.6898336105247634, 0.5179499052786559, 0.9896345610805347, 24.0, 16.0, 6.0, 1.0, 10.0, 18.0, 2.0, 47.0, 9.0, 19.0, 19.0, 21.0, 2.0, 17.0, 29.0, 21.0, 32.0, 8.0, 25.0, 17.0, 5.0, 14.0, 9.0, 18.0, 7.0, 34.0, 18.0, 6.0, 37.0, 14.0, 5.0, 16.0, 13.0, 28.0, 25.0, 16.0, 7.0, 54.0, 5.0, 20.0, 8.0, 52.0, 10.0, 16.0, 15.0, 17.0, 13.0, 10.0, 4.0, 6.0, 23.0, 7.0, 6.0, 29.0, 9.0, 37.0, 10.0, 29.0, 16.0, 22.0]]\n"
     ]
    }
   ],
   "source": [
    "Test_des_list=[]\n",
    "Test_hue_arr=[]\n",
    "Test_data='dataset\\\\test\\\\*.jpg'\n",
    "'''\n",
    "Apple_training_data='dataset\\\\Apples\\\\Test\\\\*.jpg'\n",
    "Orange_training_data='dataset\\\\Oranges\\\\Test\\\\*.jpg'\n",
    "Mango_training_data='dataset\\\\Mangoes\\\\Test\\\\*.jpg'\n",
    "'''\n",
    "for file in glob.glob(Test_data):    \n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contrast, homogeneity, energy, correlation= get_all_glcm_features((img_gray * 255).astype(np.uint8))\n",
    "    kpts, des = sift.detectAndCompute(img_gray,None)\n",
    "    if len(kpts) < 1:\n",
    "        no_kpts = np.zeros((1, sift.descriptorSize()), np.float32)\n",
    "        Test_des_list.append((file, no_kpts))\n",
    "    else:\n",
    "        Test_des_list.append((file, des)) \n",
    "    h,s,v=cv2.split(img)\n",
    "    hue_mean=np.mean(h)  #calculate the mean of hue channel of each image\n",
    "    hue_var=np.var(h) \n",
    "    flatten_h = list(np.concatenate(h).flat)\n",
    "    hue_skewness=skew(flatten_h)\n",
    "    image_hue_info=[]\n",
    "    image_hue_info.append(hue_mean)\n",
    "    image_hue_info.append(hue_var)\n",
    "    image_hue_info.append(hue_skewness)\n",
    "    #######################################################################\n",
    "    image_hue_info.append(contrast[0][0])\n",
    "    image_hue_info.append(homogeneity[0][0])\n",
    "    image_hue_info.append(energy[0][0])\n",
    "    image_hue_info.append(correlation[0][0])\n",
    "    #########################################################################\n",
    "    Test_hue_arr.append(image_hue_info) \n",
    "\n",
    "\n",
    "\n",
    "    # Stack all the descriptors vertically in a numpy array\n",
    "descriptors = Test_des_list[0][1]\n",
    "for file, descriptor in Test_des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "\n",
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)\n",
    "\n",
    "k = 60  #k means awal 60 clusters\n",
    "voc, variance = kmeans(descriptors_float, k, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Test_features = np.zeros((len(Test_hue_arr), k), \"float32\")\n",
    "for i in range(len(Test_hue_arr)):\n",
    "    words, distance = vq(Test_des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        Test_features[i][w] += 1\n",
    "\n",
    "\n",
    "\n",
    "#Test_features_scaled = scale(Test_features.tolist())\n",
    "#print(Test_features[0],Test_features_scaled[0])\n",
    "\n",
    "#Test_hue_arr_scaled = scale(Test_hue_arr)\n",
    "#print(Test_hue_arr[0],Test_hue_arr_scaled[0])\n",
    "\n",
    "Test_all_features=np.concatenate((Test_hue_arr,Test_features.tolist()),axis=1).tolist()\n",
    "print(Test_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf ['Apple']\n"
     ]
    }
   ],
   "source": [
    "#predict the fruit type in a new image\n",
    "#print(\"LINEAR\",clf_linear.predict(Test_all_features))\n",
    "print(\"rbf\",clf_svm_rbf.predict(Test_all_features))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d4cbe4fe6a33e4d72c9a2990f07f1aeb20aae8182e4dceeb23ed7c7096de238"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
